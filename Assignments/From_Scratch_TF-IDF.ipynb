{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kmistri-TF-IDF from Scratch Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsnogjXUQu1K"
      },
      "source": [
        "# NOTE:\n",
        "\n",
        "1. Please implement the TFIDF function such that for each word in a sentence, its corresponding tfidf value is assigned. Thus a 4 x 6 sized matrix should be returned where the rows represent sentences and the columns represent words. We wish to keep it simple in the beginning.\n",
        "\n",
        "2. In reality the TFIDF function should return a matrix where the rows represent sentences and the columns represent words (ie: Features). Every sentence vector in this matrix will be 'd' dimensional, where d = number of unique words in the corpus (ie: Vocabulary).\n",
        "Every position/cell in a sentence vector correponds to a particular word in the vocabulary. If the word is not present in the current sentence, we assign a value of 0 to that cell, else we assign the TFIDF value."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vrZdUum2xPk"
      },
      "source": [
        "# **Implement TF-IDF from scratch**\n",
        "\n",
        "In this assignment, you will implement TF-IDF vectorization of text from scratch using only Python and inbuilt data structures. You will then verify the correctness of the your implementation using a \"grader\" function/cell (provided by us) which will match your implmentation.\n",
        "\n",
        "The grader fucntion would help you validate the correctness of your code. \n",
        "\n",
        "Please submit the final Colab notebook in the classroom ONLY after you have verified your code using the grader function/cell.\n",
        "\n",
        "**(FAQ) Why bother about implementing a function to compute TF-IDF when it is already available in major libraries?**\n",
        "\n",
        "Ans.\n",
        "1. It helps you improve your coding proficiency.\n",
        "2. It helps you obtain a deeper understanding of the concepts and how it works internally. Knowledge of the internals will also help you debug problems better.\n",
        "3. A lot of product based startups and companies do focus on this in their interviews to gauge your depth and clarity of understanding along with your programming skills. Hence, most top universities have implementations of some ML algorithms/concepts as mandatory assignments.\n",
        "\n",
        "**NOTE: DO NOT change the \"grader\" functions or code snippets written by us.Please add your code in the suggested locations.**\n",
        "\n",
        "Ethics Code:\n",
        "1. You are welcome to read up online resources to implement the code. \n",
        "2. You can also discuss with your classmates on the implmentation over Slack.\n",
        "3. But, the code you wirte and submit should be yours ONLY. Your code will be compared against other stduents' code and online code snippets to check for plagiarism. If your code is found to be plagiarised, you will be awarded zero-marks for all assignments, which have a 10% wieghtage in the final marks for this course."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxSRJ4KT3OMw"
      },
      "source": [
        "# Corpus to be used for this assignment\n",
        "\n",
        "corpus = [\n",
        "     'this is the first document mostly',\n",
        "     'this document is the second document',\n",
        "     'and this is the third one',\n",
        "     'is this the first document here',\n",
        "]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYoKXNsU3nhO"
      },
      "source": [
        "# Please implement this fucntion and write your code wherever asked. Do NOT change the code snippets provided by us.\n",
        "import numpy as np\n",
        "from math import log\n",
        "\n",
        "def computeTFIDF (corpus):\n",
        "  \"\"\"Given a list of sentences as \"corpus\", return the TF-IDF vectors for all the \n",
        "  sentences in the corpus as a numpy 2D matrix. \n",
        "  \n",
        "  Each row of the 2D matrix must correspond to one sentence \n",
        "  and each column corresponds to a word in the text corpus. \n",
        "  \n",
        "  Please order the rows in the same order as the \n",
        "  sentences in the input \"corpus\". \n",
        "    \n",
        "  Ignore puncutation symbols like comma, fullstop, \n",
        "  exclamation, question-mark etc from the input corpus.\n",
        "  \n",
        "  For e.g, If the corpus contains sentences with these \n",
        "  9 distinct words, ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this'], \n",
        "  then the first column of the 2D matrix will correpsond to word \"and\", the second column will \n",
        "  correspond to column \"document\" and so on. \n",
        "  \n",
        "  Write this function using only basic Python code, inbuilt Data Structures and  NumPy ONLY.\n",
        "\n",
        "  Implement the code as optimally as possible using the inbuilt data structures of Python.\n",
        "  \"\"\"\n",
        "\n",
        "  ##############################################################\n",
        "  ####   YOUR CODE BELOW  as per the above instructions #######\n",
        "  ##############################################################\n",
        "  tf_idf_mat=[]\n",
        "\n",
        "  total_documents_in_corpus=len(corpus)\n",
        "  # Creating Corpus\n",
        "  corpus_words=[]\n",
        "  for doc in corpus:\n",
        "    doc_words=doc.split(\" \")\n",
        "    doc_words=[word.lower() for word in doc_words ]\n",
        "    for word in doc_words:\n",
        "      corpus_words.append(word.lower())\n",
        "  \n",
        "  term, counts = np.unique(np.array(corpus_words),return_counts=True)\n",
        "  corpus_dict=dict(zip(term, counts))\n",
        "  \n",
        "  # Total unique words in corpus \n",
        "  total_unique_words_in_corpus=len(corpus_dict)\n",
        "  print(corpus_dict)\n",
        "  \n",
        "  # Counting word in document (Not the frequency) for IDF calculations\n",
        "  # dictionary= { word : count of documents where it is present from corpus }\n",
        "  word_present_in_n_docs={}\n",
        "\n",
        "  for word in corpus_dict:\n",
        "    for doc in corpus:\n",
        "      if word.lower() in doc.lower():\n",
        "        if word.lower() in word_present_in_n_docs:\n",
        "          word_present_in_n_docs[word]+=1\n",
        "        else:\n",
        "          word_present_in_n_docs[word]=1\n",
        "\n",
        "  # Calculating TF-IDF\n",
        "  for doc in corpus:\n",
        "    # Splitting and changing case to lower for mitigating duplication for corpus\n",
        "    # I know that our corpus is not having Capitalized values but its good to have\n",
        "    doc_word=doc.split(\" \")\n",
        "    doc_word=[word.lower() for word in doc_word ]\n",
        "    current_doc_length=len(doc_word)\n",
        "\n",
        "    # Dictionary for the cur doc words count \n",
        "    unique, counts = np.unique(np.array(doc_word),return_counts=True)\n",
        "    curr_doc_word_counts=dict(zip(unique, counts))\n",
        "\n",
        "    tf_idf_doc_vec=[]\n",
        "    for word in doc_word:\n",
        "      # Calculating TF\n",
        "      word_count_in_current_doc=curr_doc_word_counts[word]\n",
        "      tf_val_in_curr_word_doc=word_count_in_current_doc/current_doc_length\n",
        "\n",
        "      # Calculating IDF\n",
        "      idf_val_in_curr_word_doc=log(total_documents_in_corpus/word_present_in_n_docs[word])\n",
        "\n",
        "      # Calculating TF-IDF\n",
        "      tf_idf_val=round((tf_val_in_curr_word_doc*idf_val_in_curr_word_doc),2)\n",
        "      tf_idf_doc_vec.append(tf_idf_val)\n",
        "      \n",
        "    tf_idf_mat.append(tf_idf_doc_vec)\n",
        "    \n",
        "    tf_idf=np.array(tf_idf_mat)\n",
        "  return tf_idf\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZ_hmMn92bEe"
      },
      "source": [
        "# Grader Cell\n",
        "Please execute the following Grader cell to verify the correctness of your above implementation. This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct, else, it will print \"Failed\". Make sure you get a \"Success\" before you submit the code in the classroom."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUYmXFjfu53i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "248f4a25-f4a2-4030-c003-22ed1d3583cb"
      },
      "source": [
        "###########################################\n",
        "## GRADER CELL: Do NOT Change this.\n",
        "# This cell will print \"Success\" if your implmentation of the computeTFIDF() is correct.\n",
        "# Else, it will print \"Failed\"\n",
        "###########################################\n",
        "import numpy as np\n",
        "\n",
        "# compute TF-IDF using the computeTFIDF() function\n",
        "X_custom = computeTFIDF(corpus)\n",
        "\n",
        "# Reference grader array - DO NOT MODIFY IT\n",
        "X_grader = np.array(\n",
        "    [[0, 0, 0, 0.12, 0.05, 0.23],\n",
        "     [0, 0.1, 0, 0, 0.23, 0.1],\n",
        "     [0.23, 0, 0, 0, 0.23, 0.23],\n",
        "     [0, 0, 0, 0.12, 0.05, 0.23]]\n",
        "     )\n",
        "\n",
        "# compare X_grader and X_custom\n",
        "comparison = ( X_grader == X_custom )\n",
        "isEqual = comparison.all()\n",
        "\n",
        "if isEqual:\n",
        "  print(\"******** Success ********\")\n",
        "else:\n",
        "  print(\"####### Failed #######\")\n",
        "  print(\"\\nX_grader = \\n\\n\", X_grader)\n",
        "  print(\"\\n\",\"*\"*50)\n",
        "  print(\"\\nX_custom = \\n\\n\", X_custom)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'and': 1, 'document': 4, 'first': 2, 'here': 1, 'is': 4, 'mostly': 1, 'one': 1, 'second': 1, 'the': 4, 'third': 1, 'this': 4}\n",
            "******** Success ********\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KnzKuIYeAEJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
